{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73cf7fad-e340-45e9-ba7c-c078439a6de2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Update Parameters Here\n",
    "\"\"\"\n",
    "COLLECTION = \"Quaks\"\n",
    "P_VAL = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3fe69ff-9d95-45a7-9a29-7bd3965eb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Mon Sep 13 16:47:06 2021\n",
    "KS test on table that has minting accounts and rarity data\n",
    "@author: nbax1\n",
    "\"\"\"\n",
    "\n",
    "from scipy import stats\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import config\n",
    "\n",
    "\"\"\"\n",
    "Plot params\n",
    "\"\"\"\n",
    "plt.rcParams.update({\"figure.facecolor\": \"white\", \"savefig.facecolor\": \"white\"})\n",
    "\n",
    "\"\"\"\n",
    "Helper Functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generateSyntheticDataset(size, maxRarity, mode=\"default\"):\n",
    "    \"\"\"\n",
    "    generates a synthetic dataset for sanity checks\n",
    "    MODIFY THIS FUNCTION IF YOU'RE ANALYZING A COLLECTION WITH NON-UNIFORM DISTRIBUTION\n",
    "    inputs:\n",
    "        size: number of NFTs purchased by synthetic buyer\n",
    "        maxRarity: should be the number of NFTs in synthetic collection\n",
    "        mode: default buys at random. If mode is a float then x% of buys will be in top 5% of rarity\n",
    "    \"\"\"\n",
    "    if mode == \"default\":\n",
    "        # =modify this to select sequential token_ids or only from a subset of collection\n",
    "        random_sample = random.sample(range(1, maxRarity), size)\n",
    "\n",
    "        return np.array(random_sample)\n",
    "    else:\n",
    "        num_rigged_buys = int(mode * size)\n",
    "        rigged_buys = random.sample(range(1, int(maxRarity / 20)), num_rigged_buys)\n",
    "        random_buys = random.sample(range(1, maxRarity), size - len(rigged_buys))\n",
    "        return np.array(rigged_buys + random_buys)\n",
    "\n",
    "\n",
    "def getRarityArray(data, account):\n",
    "    \"\"\"\n",
    "    inputs: dataframe with columns to_account and rarity\n",
    "    account: the account to get data from\n",
    "    returns: array with rarity rank of every NFT minted by an account\n",
    "    \"\"\"\n",
    "    return np.array(data[data[\"to_account\"] == account][\"rank\"])\n",
    "\n",
    "\n",
    "def cal_average(num):\n",
    "    \"\"\"\n",
    "    inputs:\n",
    "        data: dataframe with columns to_account and rarity\n",
    "    \"\"\"\n",
    "    sum_num = 0\n",
    "    for t in num:\n",
    "        sum_num = sum_num + t\n",
    "\n",
    "    avg = sum_num / len(num)\n",
    "    return avg\n",
    "\n",
    "\n",
    "def find_anomalies(data, threshold=2, num_replicates=1):\n",
    "    \"\"\"\n",
    "    Prints KS test results for every account in collection that was anomalously lucky\n",
    "    inputs:\n",
    "        data: dataframe with column 'to_account' for account that minted NFT, and 'rank' for rarity ranking\n",
    "        threshold: integer for minimum number of NFTs minted by account to be included in analysis\n",
    "        num_replicates: set to 1 if not generating synthetic datasets (used when rarity is non-uniformly distributed)\n",
    "\n",
    "    \"\"\"\n",
    "    vc = data.to_account.value_counts()\n",
    "\n",
    "    num_datapoints = len(data)\n",
    "    grifters_data = []\n",
    "\n",
    "    for account in vc[vc > threshold].index:\n",
    "        lowest_list = []\n",
    "\n",
    "        rarity_array = getRarityArray(data, account)\n",
    "        num_minted = len(rarity_array)\n",
    "        num_anomalies = 0\n",
    "        p_values = []\n",
    "        for x in range(0, num_replicates):\n",
    "            \"\"\"\n",
    "            #make synthetic dataset to compare to actual data\n",
    "            synthetic = generateSyntheticDataset(num_minted, num_datapoints)\n",
    "            \"\"\"\n",
    "            # generate uniform distribution\n",
    "            synthetic = np.array(range(1, num_datapoints + 1))\n",
    "            ks = stats.kstest(rvs=synthetic, cdf=rarity_array, alternative=\"less\")\n",
    "\n",
    "            if ks[1] < P_VAL:  # raise and you will get more hits\n",
    "                num_anomalies += 1\n",
    "                p_values.append(ks[1])\n",
    "\n",
    "        if num_anomalies >= num_replicates * 0.8:  # arbitrary threshold\n",
    "            print(account + \",\" + str(cal_average(p_values)))\n",
    "            print(\n",
    "                \"num_transactions: \"\n",
    "                + str(len(data[data[\"to_account\"] == account][\"txid\"].unique()))\n",
    "            )\n",
    "            print(\"num_minted:\" + str(len(data[data[\"to_account\"] == account])))\n",
    "            # outputs lowest rank for each mint transaction\n",
    "            for transaction in data[data[\"to_account\"] == account][\"txid\"].unique():\n",
    "                lowest_rank = min(data[data[\"txid\"] == transaction][\"rank\"])\n",
    "                token_id = data.loc[data[\"rank\"] == lowest_rank, \"TOKEN_ID\"].values[0]\n",
    "                lowest_list.append([lowest_rank, token_id])\n",
    "\n",
    "            print(\"{rank, token_id}\")\n",
    "            print(lowest_list)\n",
    "            print(\"\\n\")\n",
    "\n",
    "            # add grifter to dict\n",
    "            grifter = dict()\n",
    "            grifter[\"address\"] = account\n",
    "            grifter[\"pvalue\"] = cal_average(p_values)\n",
    "            grifter[\"num_transactions\"] = len(\n",
    "                data[data[\"to_account\"] == account][\"txid\"].unique()\n",
    "            )\n",
    "            grifter[\"num_minted\"] = len(data[data[\"to_account\"] == account])\n",
    "            grifter[\"token_list\"] = lowest_list\n",
    "            grifters_data.append(grifter)\n",
    "\n",
    "    pd.DataFrame.from_records(grifters_data).to_csv(\n",
    "        f\"{config.GRIFTERS_DATA_FOLDER}/{COLLECTION}_grifters.csv\", index=False\n",
    "    )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f5177-0ccb-4613-87fa-3f3b869bb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate Report\n",
    "\"\"\"\n",
    "PATH = f\"{config.MINTING_FOLDER}/{COLLECTION}_minting.csv\"\n",
    "\n",
    "data_to_analyze = pd.read_csv(PATH)\n",
    "print(\"Number of buyers:\" + str(len(data_to_analyze[\"to_account\"].unique())))\n",
    "print(\"Lucky Buyer,p\")\n",
    "print(\"\\n\")\n",
    "find_anomalies(data_to_analyze)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
