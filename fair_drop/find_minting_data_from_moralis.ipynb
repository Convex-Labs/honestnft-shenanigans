{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Update Parameters Here\n",
    "\"\"\"\n",
    "COLLECTION_NAME = \"Quaks\"\n",
    "CONTRACT = \"0x07bbdaf30e89ea3ecf6cadc80d6e7c4b0843c729\"\n",
    "CHAIN = \"eth\"\n",
    "\n",
    "\"\"\" \n",
    "Optional parameters\n",
    "\"\"\"\n",
    "\n",
    "KEEP_ALL_DATA = False  # set to TRUE to keep the raw JSON on disk\n",
    "\n",
    "MAX_RESULTS = 100  # max results per request\n",
    "TIME_DELTA = 1  # time to wait between successful calls\n",
    "TIME_DELTA_2 = 5  # time to wait after API throttling message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "A Moralis API Key is required.\n",
    "The free tier includes one and is enough to get minting data.\n",
    "\n",
    "AVAILABLE CHAINS:\n",
    "    eth, ropsten, rinkeby, goerli, kovan,\n",
    "    polygon, mumbai, bsc, bsc testnet,\n",
    "    avalanche, avalanche testnet, fantom\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "\n",
    "from utils import config\n",
    "from utils import constants\n",
    "\n",
    "\n",
    "def get_mintdata(\n",
    "    COLLECTION_NAME: str,\n",
    "    CONTRACT: str,\n",
    "    CHAIN: str,\n",
    ") -> None:\n",
    "\n",
    "    RARITY_CSV = f\"{config.RARITY_FOLDER}/{COLLECTION_NAME}_raritytools.csv\"\n",
    "\n",
    "    print(f\"Rarity data loaded from: {RARITY_CSV}\")\n",
    "    RARITY_DB = pd.read_csv(RARITY_CSV)\n",
    "    headers = {\"Content-type\": \"application/json\", \"x-api-key\": config.MORALIS_API_KEY}\n",
    "\n",
    "    print(f\"Getting minting data for {COLLECTION_NAME}\")\n",
    "    more_results = True\n",
    "    page = 1\n",
    "    start_time = time.time()\n",
    "    all_data = list()  # empty list to store data as it comes\n",
    "    cursor = \"\"\n",
    "    while more_results:\n",
    "        if cursor == \"\":\n",
    "            url = \"https://deep-index.moralis.io/api/v2/nft/{}/transfers?chain={}&format=decimal&limit={}\".format(\n",
    "                CONTRACT, CHAIN, MAX_RESULTS\n",
    "            )\n",
    "        else:\n",
    "            url = \"https://deep-index.moralis.io/api/v2/nft/{}/transfers?chain={}&format=decimal&limit={}&cursor={}\".format(\n",
    "                CONTRACT, CHAIN, MAX_RESULTS, cursor\n",
    "            )\n",
    "\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response_data = response.json()\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            cursor = response_data[\"cursor\"]\n",
    "\n",
    "            PATH = (\n",
    "                f\"{config.MINTING_FOLDER}/{COLLECTION_NAME}/{page * MAX_RESULTS}.json\"\n",
    "            )\n",
    "\n",
    "            # add new data to existing list\n",
    "            all_data.extend(response_data[\"result\"])\n",
    "\n",
    "            page += 1\n",
    "\n",
    "            # if results in this response is less than MAX_RESULTS then it's the last page\n",
    "            if len(response_data[\"result\"]) < MAX_RESULTS:\n",
    "                more_results = False\n",
    "            else:\n",
    "                time.sleep(TIME_DELTA)\n",
    "\n",
    "        elif response.status_code in [429, 503, 520]:\n",
    "            print(\n",
    "                f\"Got a {response.status_code} response from the server. Waiting {TIME_DELTA_2} seconds and retrying\"\n",
    "            )\n",
    "            time.sleep(TIME_DELTA_2)\n",
    "\n",
    "        else:\n",
    "            print(f\"status_code = {response.status_code}\")\n",
    "            print(\"Received a unexpected error from Moralis API. Closing process.\")\n",
    "            print(response.json())\n",
    "            more_results = False\n",
    "        cursor = response.json()[\"cursor\"] if \"cursor\" in response.json() else None\n",
    "        more_results = cursor != \"\"\n",
    "\n",
    "    # Save full json data to one master file\n",
    "    if KEEP_ALL_DATA:\n",
    "        folder = f\"{config.MINTING_FOLDER}/{COLLECTION_NAME}/\"\n",
    "        if not os.path.exists(folder):\n",
    "            os.mkdir(folder)\n",
    "\n",
    "        PATH = f\"{config.MINTING_FOLDER}/{COLLECTION_NAME}/{COLLECTION_NAME}.json\"\n",
    "        with open(PATH, \"w\") as destination_file:\n",
    "            json.dump(all_data, destination_file)\n",
    "\n",
    "    df = json_normalize(all_data)\n",
    "    # remove non minting rows\n",
    "    df = df.loc[df[\"from_address\"] == constants.MINT_ADDRESS]\n",
    "\n",
    "    # make sure token_id is an integer\n",
    "    df[\"token_id\"] = df[\"token_id\"].astype(int)\n",
    "\n",
    "    # add rarity rank to minting data\n",
    "    df = df.merge(RARITY_DB, left_on=\"token_id\", right_on=\"TOKEN_ID\")\n",
    "\n",
    "    # discard unwanted columns\n",
    "    df = df[\n",
    "        [\n",
    "            \"transaction_hash\",\n",
    "            \"to_address\",\n",
    "            \"token_id\",\n",
    "            \"from_address\",\n",
    "            \"Rank\",\n",
    "            \"block_timestamp\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    df.drop_duplicates(subset=[\"token_id\"], inplace=True)\n",
    "\n",
    "    # get matching columns names to HonestNFT csv format\n",
    "    df.columns = [\"txid\", \"to_account\", \"TOKEN_ID\", \"current_owner\", \"rank\", \"time\"]\n",
    "\n",
    "    # clean 'time' field to make it compatible with the csv produced by 'find_minting_data.ipynb'\n",
    "    df[\"time\"] = df[\"time\"].str.replace(\".000Z\", \"\")\n",
    "\n",
    "    df.to_csv(f\"{config.MINTING_FOLDER}/{COLLECTION_NAME}_minting.csv\")\n",
    "\n",
    "    print(\"--- %s seconds ---\" % (round(time.time() - start_time, 1)))\n",
    "    print(\"finished\")\n",
    "\n",
    "\n",
    "get_mintdata(COLLECTION_NAME, CONTRACT, CHAIN)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
