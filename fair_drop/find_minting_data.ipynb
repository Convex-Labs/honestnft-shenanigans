{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4dcf0a",
   "metadata": {},
   "source": [
    "# Find Minting Data (Moralis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "482cb9f9-a0d9-42eb-843b-936cc2594dad",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Update Parameters Here\n",
    "\"\"\"\n",
    "COLLECTION_NAME = \"Quaks\"\n",
    "CONTRACT = \"0x07bbdaf30e89ea3ecf6cadc80d6e7c4b0843c729\"\n",
    "BEFORE_TIME = \"2021-09-02T00:00:00\"  # One day after the last mint (e.g. https://etherscan.io/tx/0x206c846d0d1739faa9835e16ff419d15708a558357a9413619e65dacf095ac7a)\n",
    "\n",
    "# these should usually stay the same\n",
    "METHOD = \"raritytools\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daadd5d2-e168-4e68-a66d-6f64296d9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Created on Tue Sep 14 20:17:07 2021\n",
    "mint data. Doesn't work when Opensea's API is being shitty\n",
    "@author: nbax1, slight modifications by mdigi14\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from honestnft_utils import config\n",
    "from honestnft_utils import constants\n",
    "from honestnft_utils import opensea\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Helper Functions\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_mint_events(\n",
    "    contract: str, before_time: str, rarity_db: pd.DataFrame\n",
    ") -> pd.DataFrame:\n",
    "    data = opensea.get_opensea_events(\n",
    "        contract_address=contract,\n",
    "        account_address=constants.MINT_ADDRESS,\n",
    "        event_type=\"transfer\",\n",
    "        occurred_before=before_time,\n",
    "    )\n",
    "\n",
    "    df = pd.json_normalize(data)\n",
    "\n",
    "    df = df.loc[df[\"from_account.address\"] == constants.MINT_ADDRESS]\n",
    "    df_rar = pd.DataFrame(rarity_db)\n",
    "\n",
    "    os_tokens = df[\"asset.token_id\"].astype(int).tolist()\n",
    "    rar_tokens = df_rar[\"TOKEN_ID\"].astype(int).tolist()\n",
    "\n",
    "    set1 = set(rar_tokens)\n",
    "    set2 = set(os_tokens)\n",
    "\n",
    "    missing_tokens = list(sorted(set1 - set2))\n",
    "    if missing_tokens:\n",
    "        print(\n",
    "            f\"Missing tokens: {missing_tokens}\\nTrying to fetch event for missing tokens...\"\n",
    "        )\n",
    "\n",
    "    missing_data = []\n",
    "    for token in missing_tokens:\n",
    "        missing_data.extend(\n",
    "            opensea.get_opensea_events(\n",
    "                contract_address=contract,\n",
    "                account_address=constants.MINT_ADDRESS,\n",
    "                event_type=\"transfer\",\n",
    "                occurred_before=before_time,\n",
    "                token_id=token,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    df_missing_data = pd.json_normalize(missing_data)\n",
    "\n",
    "    # Merge missing data with rest of data\n",
    "    df_all = pd.concat([df, df_missing_data])\n",
    "\n",
    "    # make sure token_id is an integer\n",
    "    df_all[\"asset.token_id\"] = df_all[\"asset.token_id\"].astype(int)\n",
    "    RARITY_DB[\"TOKEN_ID\"] = RARITY_DB[\"TOKEN_ID\"].astype(int)\n",
    "\n",
    "    # add rarity rank to minting data\n",
    "    df_all = df_all.merge(RARITY_DB, left_on=\"asset.token_id\", right_on=\"TOKEN_ID\")\n",
    "\n",
    "    # Keep only the columns we want\n",
    "    df_all = df_all[\n",
    "        [\n",
    "            \"transaction.transaction_hash\",\n",
    "            \"to_account.address\",\n",
    "            \"asset.token_id\",\n",
    "            \"asset.owner.address\",\n",
    "            \"Rank\",\n",
    "            \"transaction.timestamp\",\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    # Rename columns\n",
    "    df_all.columns = [\n",
    "        \"txid\",\n",
    "        \"to_account\",\n",
    "        \"TOKEN_ID\",\n",
    "        \"current_owner\",\n",
    "        \"rank\",\n",
    "        \"time\",\n",
    "    ]\n",
    "    print(f\"Downloaded {df_all.shape[0]} events\")\n",
    "    return df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f3051c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing tokens: [1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 2375, 2376, 2781, 2782, 2783, 2784, 2785, 2786, 2787, 2788, 2789]\n",
      "Trying to fetch event for missing tokens...\n",
      "Downloaded 6000 events\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gerenerate Dataset\n",
    "\"\"\"\n",
    "RARITY_CSV = f\"{config.RARITY_FOLDER}/{COLLECTION_NAME}_{METHOD}.csv\"\n",
    "RARITY_DB = pd.read_csv(RARITY_CSV)\n",
    "\n",
    "mint_db = get_mint_events(CONTRACT, BEFORE_TIME, RARITY_DB)\n",
    "mint_db = mint_db.sort_values(by=[\"TOKEN_ID\"])\n",
    "mint_db.to_csv(f\"{config.MINTING_FOLDER}/{COLLECTION_NAME}_minting.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
